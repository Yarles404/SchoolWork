---
title: "303midterm1"
author: "Charles Yang 510 636 138 (This constitutes my signature)"
date: "9/24/2021"
output:
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results="hide")

library(ISLR2)
library(tidyverse)
library(ggplot2)
library(cowplot)
library(GGally)
library(car)
```
<style type="text/css">
@import url("https://cdn.jsdelivr.net/npm/bulma@0.9.3/css/bulma.min.css");
</style>

```{=html}
<article class="message is-primary">
  <div class="message-header">
    <p>1. Fill in the blanks</p>
  </div>
  <div class="message-body">
    a. irreducible error <br>
    b. r-squared value <br>
    c. Y <br>
    d. residual sum of squares <br>
    e. piecewise numerical interpolation <br>
    f. rank <br>
    g. 8 <br>
    h. the dependent variable <br>
    i. inference, prediction accuracy <br>
  </div>
</article>
```

# Question 2: Bias-Variance Decomposition

## 2a. See code
```{r a}
set.seed(1)
n = 100

x = runif(n, min=0, max=2)
error = rnorm(n, 0, 1)
y = 4 + x + x^2 + x^3 + x^4 +x^5 + error

train_set = data.frame(x, y)
```
## 2b. See code
```{r b}
m1 = lm(y~x, data=train_set)
m2 = lm(y~poly(x, degree=2), data=train_set)
m3 = lm(y~poly(x, degree=3), data=train_set)
m4 = lm(y~poly(x, degree=5), data=train_set)
m5 = lm(y~poly(x, degree=11), data=train_set)
```
```{r c}
x0 = data.frame(x = 0.9)
predict(m1, x0)
predict(m2, x0)
predict(m3, x0)
predict(m4, x0)
predict(m5, x0)
```
```{=html}
<article class="message is-primary">
  <div class="message-header">
    <p>2c. Predictions</p>
  </div>
  <div class="message-body">
    <table class="table">
      <thead>
        <tr>
          <th>Model</th> <th>Predicted</th>
        </tr>
      </thead>
      <tbody>
        <tr> <td>M1</td> <td>13.136</td> </tr>
        <tr> <td>M2</td> <td>6.593</td> </tr>
        <tr> <td>M3</td> <td>7.305</td> </tr>
        <tr> <td>M4</td> <td>7.762</td> </tr>
        <tr> <td>M5</td> <td>8.044</td> </tr>
      </tbody>
    </table>
  </div>
</article>
```

```{r d}
y_true = 4 + 0.9 + 0.9^2 + 0.9^3 + 0.9^4 +0.9^5
print(y_true)
```
```{=html}
<article class="message is-primary">
  <div class="message-header">
    <p>2d. True Value</p>
  </div>
  <div class="message-body">
    The true value of E(Y) when x = 0.9 is 7.686
  </div>
</article>
```

```{r e}
m1_pred = c()
m2_pred = c()
m3_pred = c()
m4_pred = c()
m5_pred = c()

for (i in 1:1000) {
  # Generate new Y values
  error = rnorm(n, 0, 1)
  y = 4 + x + x^2 + x^3 + x^4 +x^5 + error
  train_set = data.frame(x, y)
  
  m1 = lm(y~x, data=train_set)
  m2 = lm(y~poly(x, degree=2), data=train_set)
  m3 = lm(y~poly(x, degree=3), data=train_set)
  m4 = lm(y~poly(x, degree=5), data=train_set)
  m5 = lm(y~poly(x, degree=11), data=train_set)
  
  m1_pred = append(m1_pred, predict(m1, x0))
  m2_pred = append(m2_pred, predict(m2, x0))
  m3_pred = append(m3_pred, predict(m3, x0))
  m4_pred = append(m4_pred, predict(m4, x0))
  m5_pred = append(m5_pred, predict(m5, x0))
}

head(m1_pred, 5)
head(m2_pred, 5)
head(m3_pred, 5)
head(m4_pred, 5)
head(m5_pred, 5)
```
```{=html}
<article class="message is-primary">
  <div class="message-header">
    <p>2e. More Predictions</p>
  </div>
  <div class="message-body">
    <table class="table">
      <thead>
        <tr>
          <th>Model</th> <th>Predicted1</th> <th>Predicted2</th> <th>Predicted3</th> <th>Predicted4</th> <th>Predicted5</th>
        </tr>
      </thead>
      <tbody>
        <tr> <td>M1</td> <td>13.20976 </td> <td>13.32310 </td> <td>13.12198 </td> <td>13.17823 </td> <td>13.09776 </td> </tr>
        <tr> <td>M2</td> <td>6.522894 </td> <td>6.945454 </td> <td>6.443257 </td> <td>6.571565 </td> <td>6.648596</td> </tr>
        <tr> <td>M3</td> <td>7.682515 </td> <td>7.130041 </td> <td>7.216595 </td> <td>7.319223 </td> <td>7.305</td> </tr>
        <tr> <td>M4</td> <td>7.699971 </td> <td>8.003010 </td> <td>7.550343</td> <td>7.548204 </td> <td>7.603114 </td> </tr>
        <tr> <td>M5</td> <td>7.411132 </td> <td>8.221180 </td> <td>7.573210 </td> <td>7.394464 </td> <td>7.473157 </td> </tr>
      </tbody>
    </table>
  </div>
</article>
```

## 2f. See code
```{r f-g}
x0 = rep(0.9, 1000)
y0 = 4 + x0 + x0^2 + x0^3 + x0^4 +x0^5 + rnorm(1000, 0, 1)
test_set = data.frame(x=x0, y=y0)

m1_tMSE = mean((m1_pred - test_set$y)^2)
m2_tMSE = mean((m2_pred - test_set$y)^2)
m3_tMSE = mean((m3_pred - test_set$y)^2)
m4_tMSE = mean((m4_pred - test_set$y)^2)
m5_tMSE = mean((m5_pred - test_set$y)^2)

print(m1_tMSE)
print(m2_tMSE)
print(m3_tMSE)
print(m4_tMSE)
print(m5_tMSE)
```
```{=html}
<article class="message is-primary">
  <div class="message-header">
    <p>2g. Test MSEs</p>
  </div>
  <div class="message-body">
    <table class="table">
      <thead>
        <tr>
          <th>Model</th> <th>Test MSE</th>
        </tr>
      </thead>
      <tbody>
        <tr> <td>M1</td> <td>31.00251</td> </tr>
        <tr> <td>M2</td> <td>2.182154</td> </tr>
        <tr> <td>M3</td> <td>1.161572</td> </tr>
        <tr> <td>M4</td> <td>1.023989</td> </tr>
        <tr> <td>M5</td> <td>1.060558</td> </tr>
      </tbody>
    </table>
  </div>
</article>
```

```{r h}
our_bias = function(predicted, truth) {
  (mean(predicted) - truth)^2
}

our_var = function(predicted) {
  mean((predicted - mean(predicted))^2)
}

our_bias(m1_pred, y_true)
our_var(m1_pred)

our_bias(m2_pred, y_true)
our_var(m2_pred)

our_bias(m3_pred, y_true)
our_var(m3_pred)

our_bias(m4_pred, y_true)
our_var(m4_pred)

our_bias(m5_pred, y_true)
our_var(m5_pred)
```
```{=html}
<article class="message is-primary">
  <div class="message-header">
    <p>2h. Bias and Variance</p>
  </div>
  <div class="message-body">
    <table class="table">
      <thead>
        <tr>
          <th>Model</th> <th>Flexibility</th> <th>Bias</th> <th>Variance</th>
        </tr>
      </thead>
      <tbody>
        <tr> <td>M1</td> <td>1</td> <td>30.11536</td> <td>0.01033961</td> </tr>
        <tr> <td>M2</td> <td>2</td> <td>1.139161</td> <td>0.0200949</td> </tr>
        <tr> <td>M3</td> <td>3</td> <td>0.1356355</td> <td>0.0214243</td> </tr>
        <tr> <td>M4</td> <td>5</td> <td>5.993004e-06</td> <td>0.03181809</td> </tr>
        <tr> <td>M5</td> <td>11</td> <td>2.009825e-05</td> <td>0.06833313</td> </tr>
      </tbody>
    </table>
    
    Bias decreases as flexibility increases because the model curve can "bend" further to fit the training data better. However, this causes variance to increase because we get wildly different models between training sets. <br>
  Bias and variance are inversely related because they compete in a zero-sum game to describe the test MSE. So, if one increases, the other must decrease.
  </div> 
</article>
```
